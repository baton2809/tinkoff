# HelpSteer2 Dataset Processing

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏, –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ HelpSteer2_binarized –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.

## üìã –û–±–∑–æ—Ä

–ü—Ä–æ–µ–∫—Ç —É—Å–ø–µ—à–Ω–æ:
- ‚úÖ –ó–∞–≥—Ä—É–∑–∏–ª –¥–∞—Ç–∞—Å–µ—Ç `esfrankel17/original_HelpSteer2_binarized` —Å Hugging Face Hub
- ‚úÖ –†–∞–∑–¥–µ–ª–∏–ª –¥–∞–Ω–Ω—ã–µ –Ω–∞ train (80%) –∏ validation (20%) –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏
- ‚úÖ –û–≥—Ä–∞–Ω–∏—á–∏–ª –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –¥–æ 256 —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è OOM
- ‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–ª –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é `microsoft/DialoGPT-medium`
- ‚úÖ –°–æ—Ö—Ä–∞–Ω–∏–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª –¥–ª—è —Ä–∞–±–æ—Ç—ã –Ω–∞ M1 MacBook —Å MPS

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

- **–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤**: 8,678
- **Train dataset**: 6,942 –ø—Ä–∏–º–µ—Ä–∞ (80%)
- **Validation dataset**: 1,736 –ø—Ä–∏–º–µ—Ä–æ–≤ (20%)
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤**: 256
- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤**: 110.2
- **–°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ä–µ–π—Ç–∏–Ω–≥–∞—Ö**: 0.76

### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω —Ç–æ–∫–µ–Ω–æ–≤:
- –ö–æ—Ä–æ—Ç–∫–∏–µ (< 64 —Ç–æ–∫–µ–Ω–æ–≤): 53.2%
- –°—Ä–µ–¥–Ω–∏–µ (64-127 —Ç–æ–∫–µ–Ω–æ–≤): 9.1%
- –î–ª–∏–Ω–Ω—ã–µ (128-255 —Ç–æ–∫–µ–Ω–æ–≤): 9.2%
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ (256 —Ç–æ–∫–µ–Ω–æ–≤): 28.5%

## üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
‚îú‚îÄ‚îÄ load_helpsteer_dataset.py    # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
‚îú‚îÄ‚îÄ dataset_summary.py           # –ê–Ω–∞–ª–∏–∑ –∏ —Å–≤–æ–¥–∫–∞ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É
‚îú‚îÄ‚îÄ usage_example.py            # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
‚îú‚îÄ‚îÄ setup_libraries.py          # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è M1 MacBook
‚îú‚îÄ‚îÄ requirements.txt            # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
‚îú‚îÄ‚îÄ processed_helpsteer/        # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ train/                  # Train dataset
‚îÇ   ‚îú‚îÄ‚îÄ validation/             # Validation dataset
‚îÇ   ‚îî‚îÄ‚îÄ metadata.json           # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
‚îî‚îÄ‚îÄ README_helpsteer.md         # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
```bash
pip install -r requirements.txt
```

### 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
```bash
python load_helpsteer_dataset.py
```

### 3. –ê–Ω–∞–ª–∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
```bash
python dataset_summary.py
```

### 4. –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
```bash
python usage_example.py
```

## üíª –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ

### –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
```python
from datasets import load_from_disk
import json

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
train_dataset = load_from_disk("processed_helpsteer/train")
val_dataset = load_from_disk("processed_helpsteer/validation")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
with open("processed_helpsteer/metadata.json", "r") as f:
    metadata = json.load(f)

print(f"Train: {len(train_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
print(f"Validation: {len(val_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å DataLoader
```python
from torch.utils.data import DataLoader
import torch

def collate_fn(batch):
    return {
        'input_ids': torch.tensor([item['input_ids'] for item in batch]),
        'attention_mask': torch.tensor([item['attention_mask'] for item in batch]),
        'chosen_ratings': torch.tensor([item['chosen_rating'] for item in batch]),
        'rejected_ratings': torch.tensor([item['rejected_rating'] for item in batch])
    }

train_dataloader = DataLoader(
    train_dataset,
    batch_size=2,
    shuffle=True,
    collate_fn=collate_fn
)
```

### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
```python
# –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å –≤—ã—Å–æ–∫–æ–π —Ä–∞–∑–Ω–∏—Ü–µ–π –≤ —Ä–µ–π—Ç–∏–Ω–≥–∞—Ö
def filter_high_preference_gap(example):
    gap = example['chosen_rating'] - example['rejected_rating']
    return gap >= 0.5

filtered_train = train_dataset.filter(filter_high_preference_gap)
print(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {len(filtered_train)} –∏–∑ {len(train_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
```

## üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

### Supervised Fine-Tuning (SFT)
```python
from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=4,
    fp16=True,
    dataloader_pin_memory=False,  # –î–ª—è MPS
)
```

### Direct Preference Optimization (DPO)
```python
from trl import DPOTrainer, DPOConfig

dpo_config = DPOConfig(
    output_dir="./dpo_results",
    num_train_epochs=1,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=4,
    learning_rate=5e-7,
    fp16=True,
)
```

## üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è M1 MacBook

- **MPS –ø–æ–¥–¥–µ—Ä–∂–∫–∞**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Metal Performance Shaders
- **–≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏**: fp16, –º–∞–ª–µ–Ω—å–∫–∏–µ batch sizes, gradient accumulation
- **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã**: –ú–∞–∫—Å–∏–º—É–º 256 —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è OOM
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è**: –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å progress bars

## üìà –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

–ö–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç:
- `prompt`: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- `chosen`: –ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (JSON —Ñ–æ—Ä–º–∞—Ç)
- `chosen_rating`: –†–µ–π—Ç–∏–Ω–≥ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
- `rejected`: –û—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (JSON —Ñ–æ—Ä–º–∞—Ç)
- `rejected_rating`: –†–µ–π—Ç–∏–Ω–≥ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
- `input_ids`: –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π prompt (256 —Ç–æ–∫–µ–Ω–æ–≤)
- `attention_mask`: –ú–∞—Å–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è (256 —Ç–æ–∫–µ–Ω–æ–≤)

## üéõÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤
```python
# –í load_helpsteer_dataset.py
tokenized_train, tokenized_val = process_dataset(
    train_dataset, 
    val_dataset, 
    tokenizer, 
    max_length=512  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –Ω—É–∂–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
)
```

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è train/validation
```python
# –í load_helpsteer_dataset.py
train_dataset, val_dataset = split_dataset(
    dataset, 
    target_split, 
    test_size=0.1,  # 90/10 –≤–º–µ—Å—Ç–æ 80/20
    seed=42
)
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥—Ä—É–≥–æ–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
```python
# –í load_helpsteer_dataset.py
tokenizer = setup_tokenizer("microsoft/DialoGPT-small")  # –ò–ª–∏ –¥—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å
```

## üîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–º–µ—Ä—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π:
- **–í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ** (—Ä–∞–∑–Ω–∏—Ü–∞ ‚â• 1.0): ~25% –ø—Ä–∏–º–µ—Ä–æ–≤
- **–°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ** (—Ä–∞–∑–Ω–∏—Ü–∞ 0.5-1.0): ~35% –ø—Ä–∏–º–µ—Ä–æ–≤  
- **–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ** (—Ä–∞–∑–Ω–∏—Ü–∞ < 0.5): ~40% –ø—Ä–∏–º–µ—Ä–æ–≤

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã —Å —Ä–∞–∑–Ω–∏—Ü–µ–π –≤ —Ä–µ–π—Ç–∏–Ω–≥–∞—Ö ‚â• 0.5 –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è.

## üö® –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–∏—Å—Ç–µ–º–µ

- **Python**: 3.8+
- **PyTorch**: 2.0+ —Å MPS –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
- **Transformers**: 4.30+
- **Datasets**: 2.10+
- **–ü–∞–º—è—Ç—å**: –ú–∏–Ω–∏–º—É–º 8GB RAM (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 16GB+)
- **–î–∏—Å–∫**: ~500MB –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

1. **OOM –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ**: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ 256 —Ç–æ–∫–µ–Ω–æ–≤ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è M1 MacBook
2. **Batch size**: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å batch_size=1 —Å gradient_accumulation_steps=4
3. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ**: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
4. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è**: –î–æ—Å—Ç—É–ø–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π

## ü§ù –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å MPS: `torch.mps.is_available()`
2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏
3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å max_length –¥–æ 128 —Ç–æ–∫–µ–Ω–æ–≤
4. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ gradient_checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
